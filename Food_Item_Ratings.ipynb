{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE : The below code uses Selenium to get reviews of a restaurant given a url. Since the time I made this, Zomato have changed their site so obviously the code won't work. You need to update the get_review_dataframe function to extract dataframe of reviews along with their ratings, rest of the code will work fineÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "import random\n",
    "import spacy\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time\n",
    "from fuzzywuzzy import fuzz \n",
    "from fuzzywuzzy import process \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer \n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re \n",
    "import numpy as np\n",
    "\n",
    "class FoodItems():\n",
    "    \n",
    "    def __init__(self, url, output_dir):\n",
    "        self.url = url\n",
    "        self.output_dir = output_dir\n",
    "    \n",
    "    def get_review_dataframe(self, number = 100, popular=True): \n",
    "        \"\"\"This function generates dataframe from url reviews with reviews as a column and rating as another column\"\"\"\n",
    "        \"\"\"Parameters :\n",
    "           number  -> number of reviews you want the dataframe to be created from (more reviews means more time to extract)\n",
    "           popular -> If all reviews are to be considered or only the popular ones. if popular = True, number doesn't matter\"\"\"\n",
    "        \"\"\"Output :\n",
    "           It returns the generated dataframe as output\"\"\"\n",
    "        browser = webdriver.Chrome(executable_path='/Users/rishabh/Downloads/chromedriver 2')\n",
    "        browser.get(self.url)\n",
    "        time.sleep(1)\n",
    "        if popular == True:\n",
    "            try:\n",
    "                while True:\n",
    "                    element = browser.find_element_by_xpath('//*[@id=\"reviews-container\"]/div[1]/div[3]/div[2]/div/div/span[1]')\n",
    "                    browser.execute_script(\"arguments[0].click();\", element)\n",
    "                    time.sleep(4)\n",
    "            except NoSuchElementException as e:\n",
    "                pass\n",
    "        else:\n",
    "            element = browser.find_element_by_xpath('//*[@id=\"selectors\"]/a[2]')\n",
    "            browser.execute_script(\"arguments[0].click();\", element)\n",
    "            time.sleep(10)\n",
    "            c = 0\n",
    "            try:\n",
    "                while c<=number:\n",
    "                    element = browser.find_element_by_xpath('//*[@id=\"reviews-container\"]/div[1]/div[3]/div/div/div[2]/div[1]/span[1]')\n",
    "                    browser.execute_script(\"arguments[0].click();\", element)\n",
    "                    c+=5\n",
    "                    time.sleep(5)\n",
    "            except NoSuchElementException as e:\n",
    "                pass\n",
    "        html = browser.page_source\n",
    "        soup1 = soup(html)\n",
    "        df = pd.DataFrame()\n",
    "        text = []\n",
    "        rating = []\n",
    "        for items in soup1.findAll('div',{'class':'rev-text'}):\n",
    "            text.append(items.text.strip('\\nRated\\xa0\\n').strip(' ').replace('\\n','. '))\n",
    "            rating.append(float(items.div['aria-label'].strip('Rated ')))\n",
    "        df['Text'] = text\n",
    "        df['Rating'] = rating\n",
    "        return df\n",
    "    \n",
    "    def get_food_dict(self, df):\n",
    "        \"\"\"This function generates dictionary with food items as keys and every review as value having that food item\"\"\"\n",
    "        \"\"\"Parameters:\n",
    "           df -> This function takes generated df from reviews as input\"\"\"\n",
    "        \"\"\"Output :\n",
    "           It returns the dictionary with food items as keys and every review as value having that food item\"\"\"\n",
    "        nlp = spacy.load(self.output_dir)\n",
    "        di = {}\n",
    "        for reviews in df['Text']:\n",
    "            for sen in sent_tokenize(reviews):\n",
    "                doc = nlp(sen)\n",
    "                for tokens in doc.ents:\n",
    "                    if tokens.text in di:\n",
    "                        li = di[tokens.text]\n",
    "                        li.append(sen)\n",
    "                        di[tokens.text] = li\n",
    "                    else:\n",
    "                        di[tokens.text] = [sen]\n",
    "        return di\n",
    "    \n",
    "    def merge_similar(self,item,li):\n",
    "        \"\"\"This is a helper function for merging similar items in reviews\"\"\"\n",
    "        send_li = []\n",
    "        for items in process.extract(item,li):\n",
    "            if items[1]>=90:\n",
    "                send_li.append(items[0])\n",
    "        return send_li\n",
    "         \n",
    "    \n",
    "    def merge_similar_dict(self,di):\n",
    "        \"\"\"This function merges similar items extracted by NER model\"\"\"\n",
    "        \"\"\"Parameter :\n",
    "           di -> dictionary of items as keys and reviews as values\"\"\"\n",
    "        \"\"\"Output :\n",
    "           Return updated dictionary\"\"\"\n",
    "        li = []\n",
    "        for items in di:\n",
    "            li.append(items)\n",
    "        d = {}\n",
    "        notin = []\n",
    "        for i in di:\n",
    "            if i in notin:\n",
    "                continue\n",
    "            k = self.merge_similar(i,li)\n",
    "            notin.extend(k)\n",
    "            ji = []\n",
    "            for it in k:\n",
    "                ji.extend(di[it])\n",
    "            try:\n",
    "                itt = max(k, key=len)\n",
    "                d[itt] = ji \n",
    "            except:\n",
    "                continue\n",
    "        return d\n",
    "        \n",
    "    def get_numerical_rating(self, items, item_name):\n",
    "        \"\"\"This function is a helper function to generate rating for reviews having the format Number/Number \n",
    "           example : 4.5/5 or 4/5 etc.\"\"\"\n",
    "        rat = 0\n",
    "        rating_regex = re.compile(r'[+-]?([0-9]*[.])?[0-9]+\\/[+-]?([0-9]*[.])?[0-9]+')\n",
    "        lh, _, rh = items.partition(item_name)\n",
    "        rh = rh.split()[:2]\n",
    "        rh = ' '.join(rh)\n",
    "        mo = rating_regex.search(rh)\n",
    "        if mo!= None:\n",
    "            rat = mo.group().split('/')[0]\n",
    "        return float(rat)\n",
    "    def get_sentence_rating(self, items):\n",
    "        \"\"\"This function is a helper function to generate rating based on sentiment analysis from vader sentiment\"\"\"\n",
    "        sid_obj = SentimentIntensityAnalyzer() \n",
    "        sentiment_dict = sid_obj.polarity_scores(items)\n",
    "        z = (sentiment_dict['compound'] + 1)/4 * 10\n",
    "        z = float(\"{0:.2f}\".format(z))\n",
    "        return z\n",
    "    def get_ratings(self, li, item_name):\n",
    "        \"\"\"This function generates ratings for an item in dictionary\"\"\"\n",
    "        l2 = []\n",
    "        for items in li:\n",
    "            rating = self.get_numerical_rating(items,item_name)\n",
    "            if rating!=0:\n",
    "                l2.append(rating)\n",
    "            else:\n",
    "                rating = self.get_sentence_rating(items)\n",
    "                l2.append(rating)\n",
    "        return (sum(l2)/len(l2))\n",
    "    \n",
    "    def generate_ratings(self,d):\n",
    "        \"\"\"This function generates ratings for every item\"\"\"\n",
    "        d2 = {}\n",
    "        for items in d:\n",
    "            d2[items] = np.nan\n",
    "        for items in d:\n",
    "            d2[items] = self.get_ratings(d[items],items)\n",
    "        return (sorted(d2.items(), key = lambda kv:(kv[1], kv[0]),reverse=True))  \n",
    "    \n",
    "    def final(self, number = 100, popular = True):\n",
    "        \"\"\"This function compiles all the functions together\"\"\"\n",
    "        df = self.get_review_dataframe(number = number, popular = popular)\n",
    "        di = self.get_food_dict(df = df)\n",
    "        d = self.merge_similar_dict(di=di)\n",
    "        output = self.generate_ratings(d=d)\n",
    "        return output\n",
    "        \n",
    "def main_function(url,output_dir, number=100, popular=True):\n",
    "    \"\"\"Main function to be called to generated dictionary with items extracted and their ratings\n",
    "    Parameters :\n",
    "    url        ->   url of restaurant from zomato consisting of reviews\n",
    "    output_dir ->   directory where custom NER model is saved\n",
    "    number     ->   number of reviews to consider to be used for getting food items\n",
    "    popular    ->   Whether to extract the reviews from only popular section or all reviews\"\"\"\n",
    "    obj = FoodItems(url = url, output_dir = output_dir)\n",
    "    final = obj.final(number = number, popular = popular)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Applications/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '?']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: ':)']\n",
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: 'â¤']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('mutton seekh kabab', 4.3),\n",
       " ('fish fingers', 4.3),\n",
       " ('tandoori chicken', 4.06),\n",
       " ('sweet corn', 4.06),\n",
       " ('mushrooms', 4.06),\n",
       " ('Candle light concept', 4.06),\n",
       " ('chicken, prawn', 3.9699999999999998),\n",
       " ('make', 3.96),\n",
       " ('delight', 3.96),\n",
       " ('CP', 3.93),\n",
       " ('Desserts', 3.9299999999999997),\n",
       " ('pineapple pastry', 3.8549999999999995),\n",
       " ('dal makhni', 3.82),\n",
       " ('chicken biryani', 3.82),\n",
       " ('Main course', 3.82),\n",
       " ('Food variety', 3.73),\n",
       " ('prawns', 3.7299999999999995),\n",
       " ('paneer tikka', 3.6999999999999997),\n",
       " ('red velvet pastry', 3.65),\n",
       " ('gulab jamun', 3.65),\n",
       " ('brownie', 3.65),\n",
       " ('Virgin Mary', 3.6),\n",
       " ('virgin mojito', 3.55),\n",
       " ('tandoori Platter', 3.55),\n",
       " ('sugar toast', 3.55),\n",
       " ('rabri', 3.55),\n",
       " ('pastries', 3.55),\n",
       " ('malai', 3.55),\n",
       " ('Noodles', 3.47),\n",
       " ('Barbeque Nation', 3.445),\n",
       " ('chicken tikka', 3.4),\n",
       " ('ice creams', 3.365),\n",
       " ('tamdoori snacks', 3.34),\n",
       " ('mint chutney', 3.34),\n",
       " ('grilled corn', 3.34),\n",
       " ('Grilled tandoori snacks', 3.34),\n",
       " ('strawberry.', 3.18),\n",
       " ('butter chicken', 3.16),\n",
       " ('cake', 3.025),\n",
       " ('paan kulfi', 2.9875),\n",
       " ('uncommon chicken', 2.5),\n",
       " ('three mocktails', 2.5),\n",
       " ('naan.', 2.5),\n",
       " ('Moreover', 2.5),\n",
       " ('Just visit', 2.5),\n",
       " ('Punch', 2.05),\n",
       " ('climate gets', 1.43)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Uses URL of restaurant with reviews page selected as one parameter\n",
    "### Uses directory where NER model is stored as other parameter\n",
    "main_function(url = 'https://www.zomato.com/ncr/barbeque-nation-connaught-place-new-delhi/reviews', output_dir = '/Users/rishabh/Desktop/ProjectZomato/FoodNER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outputs look decent enough, obviously with a model of high precision and some preprocessing on text being fed to the model, we can expect it to perform even better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting reviews of restaurant like this is not the best method obviously since I also suffered this -> zomato changed their site leaving my review extraction code worthless ! You can definitely switch to a better option like using their API to get the reviews as text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
